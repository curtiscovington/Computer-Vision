{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3cf8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note to Curtis: While I did initially copy/paste the example, I removed the line drawing (so it just shows the circle\n",
    "#being tracked without it's trajectory), as well as all the other filler that comes along with that, added your \n",
    "#code to checking what quadrent the circle is in during the loop, removed the initial feature finding and instead \n",
    "#initialize to x,y=(1,1) and of course allow user to click a point in the imshow to track that point (in draw_circle).\n",
    "#So I would personally say this is sufficiently transformative, and then once you add it to the class it should be\n",
    "#fine in terms of being our own work, but I still would leave the credit below, even though it will be clear we\n",
    "#modified it enough to call it our own\n",
    "\n",
    "#credit for inspiration and default param values: https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "import pyautogui\n",
    "\n",
    "# detects if point c is to the left (counter-clockwise) of the line segment formed by points a and b\n",
    "def isLeft(a, b, c):\n",
    "    return ((b[\"X\"] - a[\"X\"])*(c[\"Y\"] - a[\"Y\"]) - (b[\"Y\"] - a[\"Y\"])*(c[\"X\"] - a[\"X\"])) > 0\n",
    "\n",
    "\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global mouseX,mouseY\n",
    "    mouseX = -1\n",
    "    mouseY = -1\n",
    "    if event == cv.EVENT_LBUTTONDBLCLK:\n",
    "        cv.circle(img,(x,y),100,(255,0,0),-1)\n",
    "        mouseX,mouseY = x,y\n",
    "\n",
    "cap = cv.VideoCapture(0)        \n",
    "        \n",
    "cv.namedWindow('frame')\n",
    "cv.setMouseCallback('frame',draw_circle)\n",
    "\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "  \n",
    "#LK parameters\n",
    "lk_params = dict(winSize  = (15, 15), maxLevel = 2, criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "#Random colors for circles\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "#initialize gray image\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "#initialize first point to track at arbitary (1,1) pixel\n",
    "initial_points = np.array([[[1., 1.]]], dtype=np.float32)\n",
    "\n",
    "#initialize mouse global variables\n",
    "mouseX = -1\n",
    "mouseY = -1\n",
    "current_direction = \"\"\n",
    "\n",
    "while(1):\n",
    "    #Mouse coordinates, global variables\n",
    "    if mouseX > 0 and mouseY > 0:\n",
    "        initial_points = np.array([[[mouseX, mouseY]]], dtype=np.float32)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "    \n",
    "    #gray current frame\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    #KLT algorithm\n",
    "    next_points, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, initial_points, None, **lk_params)\n",
    "    #matching_new becomes the tracked point(s) from next frame\n",
    "    #matching_old is used to trace a line from the old point(s) to matching_new point(s)\n",
    "    if next_points is not None:\n",
    "        matching_new = next_points[st==1]\n",
    "        matching_old = initial_points[st==1]\n",
    "    #put circles where tracked points are\n",
    "    for i, (new, old) in enumerate(zip(matching_new, matching_old)):\n",
    "        a, b = new.ravel()\n",
    "        frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    "    \n",
    "    # draw a red line from the upper-left corner to the lower-right corner\n",
    "    cv.line(frame, (0, 0), (width,height), (255, 0, 0), 3)\n",
    "    # draw a red line from the upper-right corner to the lower-left corner\n",
    "    cv.line(frame, (width, 0), (0,height), (255, 0, 0), 3)\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    #update old frame to be this newest frame, for next iteration\n",
    "    old_gray = frame_gray.copy()\n",
    "    #reshape to fit required input for OpenCV LK algorithm\n",
    "    initial_points = matching_new.reshape(-1, 1, 2)\n",
    "    #check because sometimes I had an error where initial_points or elements of it were None\n",
    "    if len(initial_points) > 0:\n",
    "        if len(initial_points[0][0]) > 1:\n",
    "            #get coordinates of tracked points (we assume/only care about the first point, as technically\n",
    "            #the algorithm allows for multiple tracked points, hence the [0][0] part, but the first point\n",
    "            #will be the tracked point that determines where to turn the snake)\n",
    "            x_coord = int(initial_points[0][0][0])\n",
    "            y_coord = int(initial_points[0][0][1])\n",
    "            \n",
    "            leftLine = True\n",
    "            rightLine = True\n",
    "\n",
    "            leftLine = isLeft({\"X\": 0, \"Y\": 0}, {\"X\": width, \"Y\": height}, {\"X\": x_coord, \"Y\": y_coord})\n",
    "            rightLine = isLeft({\"X\": width, \"Y\": 0}, {\"X\": 0, \"Y\": height}, {\"X\": x_coord, \"Y\": y_coord})\n",
    "            #Note to Curtis: I add the \"and current_direction !=\" check to avoid continuously calling\n",
    "            #pyautogui, which is an expensive call. I can tell because as I move my tracked finger from\n",
    "            #one quadrant to another, I see a bit of lag without this check\n",
    "            if (leftLine and rightLine) and current_direction != \"left\":\n",
    "                pyautogui.press(\"left\")\n",
    "                current_direction = \"left\"\n",
    "            elif (not leftLine and not rightLine) and current_direction != \"right\":\n",
    "                pyautogui.press(\"right\")\n",
    "                current_direction = \"right\"\n",
    "            elif (leftLine and not rightLine) and current_direction != \"down\":\n",
    "                pyautogui.press(\"down\")\n",
    "                current_direction = \"down\"\n",
    "            elif (not leftLine and rightLine) and current_direction != \"up\":\n",
    "                pyautogui.press(\"up\")\n",
    "                current_direction = \"up\"\n",
    "    \n",
    "    keyboard = cv.waitKey(1)\n",
    "    if keyboard > 0:\n",
    "        cap.release()\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917af4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
